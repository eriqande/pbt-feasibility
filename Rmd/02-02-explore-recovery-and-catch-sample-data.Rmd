---
title: "Exploring Recovery and Catch-Sample Data"
author: "Eric C. Anderson"
date: "November 18, 2014"
output:
  html_document:
    fig_width: 10
    fig_height: 8
    toc: yes
---

```{r, echo=FALSE, include=FALSE}
library(knitr)
opts_knit$set(root.dir = '..')
```

```{r, echo=FALSE, include=FALSE}
# load libraries, etc
library(ggplot2)
library(lubridate)
library(dplyr)
library(reshape2)
library(stringr)
source("R/rmis_cleaning.R")
```


## Initial Maneuvers

Here we look at some properties to make sure that we got everything we wanted:
```{r, cache=TRUE}
# load it in
chin_rec <- readRDS("data/chinook_recoveries.rds")
dim(chin_rec)
```
This accords well with what the RMIS data base tells us when we query All Recoveries for 2002-2012 on chinook:
```
Your All Recoveries query retrieved too many rows (1452480)
```

Let's grab the catch-sample data too:
```{r, cache=TRUE}
catch_samp <- readRDS("data/catch_sample.rds")
```

### Sizes of catch samples
First I want to look very crudely at the first-mark sample size vs the first-mark obs adclips:
```{r}
ggplot(data = catch_samp) + 
    geom_point(aes(x = mr_1st_sample_size, y = mr_1st_sample_obs_adclips, color = reporting_agency))

```

OK, that shows us that some of the samples are pretty much all ad-clipped, and some of them are far from being all
ad-clipped.

Another interesting question then is how many of the adclipped, sampled fish yielded recovered and decoded coded
wire tags, broken out by Electronic versus Visual detection:
```{r}
ggplot(data = catch_samp) + 
    geom_abline(intercept = 0, slope = 1) +
    geom_point(aes(x = mr_1st_sample_obs_adclips, y = number_recovered_decoded, color = reporting_agency)) + 
    facet_wrap(~ detection_method)
```

OK, since there are so many reporting agencies, and the colors are hard to discern, it would be nice to know how many 
of the points come from each of the agencies.  Since many rows have been dropped due to missing data, I would
like to reflect that.
```{r}
ff <- filter(catch_samp, !is.na(mr_1st_sample_obs_adclips), !is.na(number_recovered_decoded))
ggplot(ff, aes(x = reporting_agency, fill = reporting_agency)) + geom_bar() + 
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
```

OK, that is interesting.  It suggests to me that CDFW and CDFO aren't really listing the number of observed adclips 
or the number recovered decoded.  So, what if we don't filter and just look at who has the most records.
```{r}
ggplot(catch_samp, aes(x = reporting_agency, fill = reporting_agency)) + geom_bar() + 
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
```

All right, that just shows us that CDFO and CDFW just don't have that many catch-sample records.  That might be 
because each of their catch samples includes more fish.

So, what we will want to do here is actually count up the number of fish from each agency in the recovery data
base (splitting them out between status 1 recoveries and otherwise)
```{r}
chin_rec$tag_status <- factor(tag_status_levels()[as.character(chin_rec$tag_status)], levels = unname(tag_status_levels()))
tag_nums <- chin_rec %>%
  group_by(run_year, reporting_agency, tag_status, detection_method) %>% 
  tally()
ggplot(tag_nums, aes(x = reporting_agency, y = n, fill = tag_status)) +
  geom_bar(stat = "identity") +
  guides(fill = guide_legend(reverse = TRUE)) +
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) + 
  facet_wrap(~ run_year + detection_method, ncol = 2)
```

That is a nice graphic.  It shows that ADFG and CDFO have real problems with ad-clipped fish that don't have a CWT,
but only in fisheries that don't use electronic detection (E = electronic, V = visual). OK.  That makes sense.

So, I still feel like I need to try to figure out how the numbers in the catch_sample file relate to the
tallies that I could make in the recovery data base.


### What is a catch-sample anyway?

Are there multiple catch-samples with the same code (just on different dates, etc?)
```{r}
catch_samp %>% 
  group_by(catch_sample_id) %>%
  tally() %>%
  select(n) %>%
  table()
```

### Let's focus on a smaller subset

I am curious about how many of the no-CWT fish in CDFO's visual samples are from hatcheries that do have some tagging, and how many are unassociated releases.  I think now is a good time to drill down and focus on just one
handful of recoveries, before scaling back up to everything.

So, some initial looks:
```{r}

# looks like we can filter down to one location for fun
cana <- catch_samp %>% 
  filter(reporting_agency == "CDFO", catch_year == 2012, catch_location_code == "2MN06")

# where is that?
locs <- tbl_df(read.csv("data/locations.csv", stringsAsFactors = F, na.strings = ""))
locs %>% filter(location_code == "2MN06")

# Catch Region 6:  That is informative....not!
```
So, it is really interesting to look closely at all of these records in `cana`.  I don't quite understand how they are recovering more CWTs in some of the fisheries than they observed ad-clips.  Are they doing some sort of electronic detection? No, they aren't.  So whey are there these discrepancies.  I'll have to look into this.

```{r}
# have a look at this particular fishery:
chin_rec %>% filter(catch_sample_id == "00061125", run_year == 2012) %>% group_by(tag_status) %>% tally()

# those are the numbers we see in cana, I am pretty sure.  But 
# the discrepancy between these numbers and the number of ad-clipped fish
# observed must be because the ad-clip status is not well
# known for many of them,
chin_rec %>% filter(catch_sample_id == "00061125", run_year == 2012) %>% group_by(tag_status, recorded_mark) %>% tally()
```

Here we can get the number of recovered ones for each year and catch sample id:
```{r}
cana %>% 
  select(catch_year, catch_sample_id, starts_with("number_recovered")) %>% 
  reshape2::melt(id.vars = c("catch_year", "catch_sample_id"), na.rm = TRUE) %>%
  arrange(catch_sample_id)
```
It would be pretty easy to compare these to what we have in the recovery data base, and also check the mark codes on those fish.


## Looking at locations of location codes

This is partly as a project to show to the R class.  Here is what I want to do:

1. Find all the location codes from which chinook were recovered in 2000 to 2012.
2. Parse those codes into their constituent parts
3. Filter them down to just the marine catch and effort locations that have lat-longs.
4. Then for each state/province, plot all of the location codes, but color the points according to 
sector, or area, etc.  Just to see how they are aggregated into different sectors and areas.

### Getting the data frame together

The locations are currently called `locs` apparently.  So, let's get only those from which we have 
chinook recoveries in chin_rec
```{r}
dim(locs)
rec_locs <- locs %>%
  filter(location_code %in% chin_rec$recovery_location_code)
dim(rec_locs)
```
Cool! We are now down to `nrow(rec_locs)` location codes. 

Now, we want to parse the codes into their constituent parts. Some of the codes only use the first 
eight characters or so.  Therefore I pad everything out to 18 characters with "---"'s at the right
hand end.
```{r}
tmp <- rec_locs$location_code %>%
  str_pad(width = 19, side = "right", pad = "-") %>%
  str_match("^([1-7])([MF])(.)(..)(....)(.{7})(...)$") %>%
  as.data.frame(stringsAsFactors = FALSE)

parsed_codes <- setNames(tmp[,-1], c("state_or_province",
                                     "water_type",
                                     "sector",
                                     "region",
                                     "area",
                                     "location",
                                     "sub_location"))

# and add this on 
rec_locs_full <- cbind(parsed_codes, rec_locs) %>% tbl_df
```


### Filter it to BC marine recovery locations
Should be easy:
```{r}
bcm_locs <- rec_locs_full %>%
  filter(state_or_province == "2", water_type == "M")
```
Cool, that is `nrow(bcm_locs)` locations. But we want to ditch the ones with no lat or long:
```{r}
bc_sites <- bcm_locs %>%
  filter(!is.na(latitude), !is.na(longitude))

# and while we are at it, let's tally those up
bc_sites %>%
  group_by(sector, region, area) %>%
  tally()
```

All right! That looks like the goods.  42 separate areas in BC.  That seems like it would be a reasonable
level of aggregation.  Let's send those to rep-res-course to plot them.
```{r}
saveRDS(bc_sites, file = "bc_sites.rds", compress = "xz")
```